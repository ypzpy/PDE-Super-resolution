2024-02-21 21:59:18,570 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:00:26,812 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:00:52,033 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:01:51,981 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:02:14,519 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:02:19,041 : Epoch 1/1000: Loss = 32.17597579956055
2024-02-21 22:02:23,509 : Epoch 2/1000: Loss = 29.19245147705078
2024-02-21 22:02:28,092 : Epoch 3/1000: Loss = 30.201126098632812
2024-02-21 22:02:31,601 : Epoch 4/1000: Loss = 23.40179443359375
2024-02-21 22:02:36,217 : Epoch 5/1000: Loss = 34.33214569091797
2024-02-21 22:02:40,730 : Epoch 6/1000: Loss = 39.94887924194336
2024-02-21 22:02:45,354 : Epoch 7/1000: Loss = 27.284526824951172
2024-02-21 22:02:52,148 : Epoch 8/1000: Loss = 29.72506332397461
2024-02-21 22:05:35,346 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:05:41,519 : Epoch 1/1000: Loss = 50.51777648925781
2024-02-21 22:05:48,643 : Epoch 2/1000: Loss = 33.91443634033203
2024-02-21 22:05:54,976 : Epoch 3/1000: Loss = 42.34169006347656
2024-02-21 22:05:58,917 : Epoch 4/1000: Loss = 37.603126525878906
2024-02-21 22:06:04,117 : Epoch 5/1000: Loss = 33.72003173828125
2024-02-21 22:06:09,119 : Epoch 6/1000: Loss = 38.60674285888672
2024-02-21 22:06:14,809 : Epoch 7/1000: Loss = 50.62260437011719
2024-02-21 22:06:20,623 : Epoch 8/1000: Loss = 42.11114501953125
2024-02-21 22:06:26,480 : Epoch 9/1000: Loss = 50.659873962402344
2024-02-21 22:06:32,193 : Epoch 10/1000: Loss = 37.478885650634766
2024-02-21 22:06:37,485 : Epoch 11/1000: Loss = 53.55517578125
2024-02-21 22:06:42,436 : Epoch 12/1000: Loss = 40.12400817871094
2024-02-21 22:06:47,684 : Epoch 13/1000: Loss = 32.915523529052734
2024-02-21 22:06:53,519 : Epoch 14/1000: Loss = 25.290231704711914
2024-02-21 22:06:59,979 : Epoch 15/1000: Loss = 29.964717864990234
2024-02-21 22:07:06,091 : Epoch 16/1000: Loss = 35.126853942871094
2024-02-21 22:07:13,064 : Epoch 17/1000: Loss = 39.220619201660156
2024-02-21 22:07:18,882 : Epoch 18/1000: Loss = 34.615333557128906
