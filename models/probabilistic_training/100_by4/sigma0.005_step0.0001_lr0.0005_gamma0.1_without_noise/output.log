2024-02-21 15:50:38,423 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 15:51:08,955 : Epoch 1/1000: Loss = 24838250.0
2024-02-21 15:51:29,742 : Epoch 2/1000: Loss = 25855914.0
2024-02-21 15:51:50,983 : Epoch 3/1000: Loss = 21796064.0
2024-02-21 15:52:11,712 : Epoch 4/1000: Loss = 14631294.0
2024-02-21 15:52:29,781 : Epoch 5/1000: Loss = 11143894.0
2024-02-21 15:52:46,755 : Epoch 6/1000: Loss = 8713098.0
2024-02-21 15:53:06,446 : Epoch 7/1000: Loss = 6797156.0
2024-02-21 15:53:26,858 : Epoch 8/1000: Loss = 5280686.5
2024-02-21 15:53:48,154 : Epoch 9/1000: Loss = 4503348.0
2024-02-21 15:54:09,015 : Epoch 10/1000: Loss = 3548305.5
2024-02-21 15:54:29,614 : Epoch 11/1000: Loss = 2747669.0
2024-02-21 15:54:51,061 : Epoch 12/1000: Loss = 2249961.0
2024-02-21 15:55:11,770 : Epoch 13/1000: Loss = 2357973.5
2024-02-21 15:55:32,856 : Epoch 14/1000: Loss = 2251329.5
2024-02-21 15:55:53,875 : Epoch 15/1000: Loss = 1855577.75
2024-02-21 15:58:47,827 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 15:59:29,428 : Epoch 1/1000: Loss = 29743288.0
2024-02-21 16:00:02,030 : Epoch 2/1000: Loss = 27398056.0
2024-02-21 16:00:33,175 : Epoch 3/1000: Loss = 34726028.0
2024-02-21 16:01:04,760 : Epoch 4/1000: Loss = 28660216.0
2024-02-21 16:02:16,702 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:02:50,341 : Epoch 1/1000: Loss = 27011394.0
2024-02-21 16:03:14,154 : Epoch 2/1000: Loss = 25530292.0
2024-02-21 16:03:37,959 : Epoch 3/1000: Loss = 31616740.0
2024-02-21 16:03:55,080 : Epoch 4/1000: Loss = 29165164.0
2024-02-21 16:04:18,966 : Epoch 5/1000: Loss = 34885264.0
2024-02-21 16:04:41,851 : Epoch 6/1000: Loss = 34077288.0
2024-02-21 16:05:05,893 : Epoch 7/1000: Loss = 31389920.0
2024-02-21 16:05:30,114 : Epoch 8/1000: Loss = 25282210.0
2024-02-21 16:06:04,282 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:06:34,453 : Epoch 1/1000: Loss = 42923132.0
2024-02-21 16:06:54,241 : Epoch 2/1000: Loss = 34754384.0
2024-02-21 16:07:14,925 : Epoch 3/1000: Loss = 28126496.0
2024-02-21 16:07:35,118 : Epoch 4/1000: Loss = 29393816.0
2024-02-21 16:07:55,719 : Epoch 5/1000: Loss = 24432632.0
2024-02-21 16:08:16,089 : Epoch 6/1000: Loss = 35946912.0
2024-02-21 16:14:28,508 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
