2024-02-21 16:15:09,759 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:15:39,074 : Epoch 1/1000: Loss = 34484440.0
2024-02-21 16:15:57,837 : Epoch 2/1000: Loss = 28301072.0
2024-02-21 16:16:52,948 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:17:34,012 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:18:13,084 : Epoch 1/1000: Loss = 37161864.0
2024-02-21 16:18:43,216 : Epoch 2/1000: Loss = 24067292.0
2024-02-21 16:19:12,927 : Epoch 3/1000: Loss = 26287688.0
2024-02-21 16:19:41,926 : Epoch 4/1000: Loss = 25835160.0
2024-02-21 16:20:11,876 : Epoch 5/1000: Loss = 23599980.0
2024-02-21 16:20:41,970 : Epoch 6/1000: Loss = 30583700.0
2024-02-21 16:21:10,949 : Epoch 7/1000: Loss = 24749940.0
2024-02-21 16:21:35,868 : Epoch 8/1000: Loss = 23910478.0
2024-02-21 16:22:05,287 : Epoch 9/1000: Loss = 31876620.0
2024-02-21 16:22:33,520 : Epoch 10/1000: Loss = 29854584.0
2024-02-21 16:23:01,416 : Epoch 11/1000: Loss = 26370572.0
2024-02-21 16:23:30,152 : Epoch 12/1000: Loss = 28157820.0
2024-02-21 16:24:00,102 : Epoch 13/1000: Loss = 22934524.0
2024-02-21 16:24:28,959 : Epoch 14/1000: Loss = 22954822.0
2024-02-21 16:24:55,347 : Epoch 15/1000: Loss = 22181092.0
2024-02-21 16:25:23,436 : Epoch 16/1000: Loss = 25673844.0
2024-02-21 16:25:53,284 : Epoch 17/1000: Loss = 22602110.0
2024-02-21 16:26:20,854 : Epoch 18/1000: Loss = 20730804.0
2024-02-21 16:26:49,110 : Epoch 19/1000: Loss = 14949661.0
2024-02-21 16:27:17,555 : Epoch 20/1000: Loss = 21284640.0
2024-02-21 22:56:19,181 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 22:56:31,061 : Epoch 1/1000: Loss = 27824900.0
2024-02-21 22:56:38,511 : Epoch 2/1000: Loss = 24876504.0
2024-02-21 22:56:46,504 : Epoch 3/1000: Loss = 23634684.0
2024-02-21 22:56:54,108 : Epoch 4/1000: Loss = 19612808.0
2024-02-21 22:57:02,854 : Epoch 5/1000: Loss = 24182826.0
2024-02-21 22:57:10,807 : Epoch 6/1000: Loss = 17142416.0
2024-02-21 22:57:19,763 : Epoch 7/1000: Loss = 19877664.0
2024-02-21 22:57:29,285 : Epoch 8/1000: Loss = 23696154.0
2024-02-21 22:57:38,357 : Epoch 9/1000: Loss = 15824486.0
2024-02-21 22:57:47,015 : Epoch 10/1000: Loss = 19806906.0
2024-02-21 22:57:55,944 : Epoch 11/1000: Loss = 15801292.0
2024-02-21 22:58:05,768 : Epoch 12/1000: Loss = 21744112.0
2024-02-21 22:58:14,444 : Epoch 13/1000: Loss = 13253190.0
2024-02-21 22:58:21,135 : Epoch 14/1000: Loss = 12697629.0
2024-02-21 22:58:27,881 : Epoch 15/1000: Loss = 8747661.0
2024-02-21 22:58:33,773 : Epoch 16/1000: Loss = 11461370.0
2024-02-21 22:58:42,128 : Epoch 17/1000: Loss = 12152652.0
2024-02-21 22:58:48,785 : Epoch 18/1000: Loss = 14266996.0
2024-02-21 22:58:57,595 : Epoch 19/1000: Loss = 11257018.0
2024-02-21 22:59:06,278 : Epoch 20/1000: Loss = 4848401.5
2024-02-21 22:59:14,995 : Epoch 21/1000: Loss = 4903833.0
2024-02-21 22:59:21,801 : Epoch 22/1000: Loss = 7127008.5
2024-02-21 22:59:28,313 : Epoch 23/1000: Loss = 5211545.5
2024-02-21 22:59:35,790 : Epoch 24/1000: Loss = 5381615.5
2024-02-21 23:02:49,386 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 23:03:02,454 : Epoch 1/1000: Loss = 37179012.0
2024-02-21 23:03:11,003 : Epoch 2/1000: Loss = 35765336.0
2024-02-21 23:03:19,522 : Epoch 3/1000: Loss = 35261408.0
2024-02-21 23:03:27,384 : Epoch 4/1000: Loss = 26686680.0
2024-02-21 23:03:34,699 : Epoch 5/1000: Loss = 23885938.0
2024-02-21 23:03:39,470 : Epoch 6/1000: Loss = 15626370.0
2024-02-21 23:03:45,099 : Epoch 7/1000: Loss = 11620779.0
2024-02-21 23:03:51,198 : Epoch 8/1000: Loss = 5861133.0
2024-02-21 23:03:56,210 : Epoch 9/1000: Loss = 7562109.5
2024-02-21 23:04:01,531 : Epoch 10/1000: Loss = 3960928.5
2024-02-21 23:04:07,116 : Epoch 11/1000: Loss = 2967488.75
2024-02-21 23:04:13,047 : Epoch 12/1000: Loss = 3455573.5
2024-02-21 23:04:19,193 : Epoch 13/1000: Loss = 2882386.5
2024-02-21 23:04:23,882 : Epoch 14/1000: Loss = 2599501.5
2024-02-21 23:04:30,151 : Epoch 15/1000: Loss = 2368344.5
2024-02-21 23:04:36,530 : Epoch 16/1000: Loss = 2658821.75
2024-02-21 23:04:41,557 : Epoch 17/1000: Loss = 2545685.0
2024-02-21 23:04:47,507 : Epoch 18/1000: Loss = 2256191.0
2024-02-21 23:04:54,179 : Epoch 19/1000: Loss = 2078971.125
2024-02-21 23:05:00,310 : Epoch 20/1000: Loss = 1874611.875
2024-02-21 23:05:06,903 : Epoch 21/1000: Loss = 2403024.75
2024-02-21 23:05:15,390 : Epoch 22/1000: Loss = 1639852.5
2024-02-21 23:05:23,594 : Epoch 23/1000: Loss = 2080101.375
2024-02-21 23:05:31,371 : Epoch 24/1000: Loss = 1735611.75
2024-02-21 23:05:38,935 : Epoch 25/1000: Loss = 1606233.5
2024-02-21 23:05:47,928 : Epoch 26/1000: Loss = 1301722.0
2024-02-21 23:05:54,089 : Epoch 27/1000: Loss = 1419309.625
