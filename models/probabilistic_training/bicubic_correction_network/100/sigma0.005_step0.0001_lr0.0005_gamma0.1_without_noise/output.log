2024-02-21 16:15:09,759 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:15:39,074 : Epoch 1/1000: Loss = 34484440.0
2024-02-21 16:15:57,837 : Epoch 2/1000: Loss = 28301072.0
2024-02-21 16:16:52,948 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:17:34,012 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.0005]
2024-02-21 16:18:13,084 : Epoch 1/1000: Loss = 37161864.0
2024-02-21 16:18:43,216 : Epoch 2/1000: Loss = 24067292.0
2024-02-21 16:19:12,927 : Epoch 3/1000: Loss = 26287688.0
2024-02-21 16:19:41,926 : Epoch 4/1000: Loss = 25835160.0
2024-02-21 16:20:11,876 : Epoch 5/1000: Loss = 23599980.0
2024-02-21 16:20:41,970 : Epoch 6/1000: Loss = 30583700.0
2024-02-21 16:21:10,949 : Epoch 7/1000: Loss = 24749940.0
2024-02-21 16:21:35,868 : Epoch 8/1000: Loss = 23910478.0
2024-02-21 16:22:05,287 : Epoch 9/1000: Loss = 31876620.0
2024-02-21 16:22:33,520 : Epoch 10/1000: Loss = 29854584.0
2024-02-21 16:23:01,416 : Epoch 11/1000: Loss = 26370572.0
2024-02-21 16:23:30,152 : Epoch 12/1000: Loss = 28157820.0
2024-02-21 16:24:00,102 : Epoch 13/1000: Loss = 22934524.0
2024-02-21 16:24:28,959 : Epoch 14/1000: Loss = 22954822.0
2024-02-21 16:24:55,347 : Epoch 15/1000: Loss = 22181092.0
2024-02-21 16:25:23,436 : Epoch 16/1000: Loss = 25673844.0
2024-02-21 16:25:53,284 : Epoch 17/1000: Loss = 22602110.0
2024-02-21 16:26:20,854 : Epoch 18/1000: Loss = 20730804.0
2024-02-21 16:26:49,110 : Epoch 19/1000: Loss = 14949661.0
2024-02-21 16:27:17,555 : Epoch 20/1000: Loss = 21284640.0
