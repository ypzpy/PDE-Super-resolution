2024-02-01 16:46:47,174 : Training for 1000 epoches and [GP_l, GP_sigma, ll_sigma, step_size, learning_rate] : [0.1, 0.1, 0.005, 0.0001, 0.005]
2024-02-01 16:46:59,491 : Epoch 1/1000: Loss = 88672864.0
2024-02-01 16:47:08,789 : Epoch 2/1000: Loss = 25414084.0
2024-02-01 16:47:18,107 : Epoch 3/1000: Loss = 8571696.0
2024-02-01 16:47:27,426 : Epoch 4/1000: Loss = 4812061.5
2024-02-01 16:47:36,644 : Epoch 5/1000: Loss = inf
